{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4058ca-9854-4c85-8eb1-ccf61fb5fd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xarray\n",
      "  Downloading xarray-2025.10.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.26 in /opt/miniconda3/lib/python3.12/site-packages (from xarray) (2.3.1)\n",
      "Collecting packaging>=24.1 (from xarray)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pandas>=2.2 (from xarray)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.2->xarray)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas>=2.2->xarray) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n",
      "Downloading xarray-2025.10.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-macosx_10_13_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, packaging, pandas, xarray\n",
      "\u001b[2K  Attempting uninstall: packaging━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [pytz]\n",
      "\u001b[2K    Found existing installation: packaging 23.1m \u001b[32m0/4\u001b[0m [pytz]\n",
      "\u001b[2K    Uninstalling packaging-23.1:━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [pytz]\n",
      "\u001b[2K      Successfully uninstalled packaging-23.1[0m \u001b[32m0/4\u001b[0m [pytz]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [xarray]2m3/4\u001b[0m [xarray]\n",
      "\u001b[1A\u001b[2KSuccessfully installed packaging-25.0 pandas-2.3.3 pytz-2025.2 xarray-2025.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46c90b8-df23-46c3-9780-bd2aa1b936cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.10.1\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "print(xr.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb643de3-5e87-4425-9b66-366042a65b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting copernicusmarine\n",
      "  Downloading copernicusmarine-2.2.3-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting arcosparse<0.5.0,>=0.4.2 (from copernicusmarine)\n",
      "  Downloading arcosparse-0.4.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting boto3>=1.26 (from copernicusmarine)\n",
      "  Downloading boto3-1.40.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting click!=8.2.0,>=8.0.4 (from copernicusmarine)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dask>=2022 (from copernicusmarine)\n",
      "  Downloading dask-2025.10.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting h5netcdf<2.0.0,>=1.4.0 (from copernicusmarine)\n",
      "  Downloading h5netcdf-1.7.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/miniconda3/lib/python3.12/site-packages (from copernicusmarine) (2.3.1)\n",
      "Collecting pydantic<3.0.0,>=2.9.1 (from copernicusmarine)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting pystac>=1.8.3 (from copernicusmarine)\n",
      "  Downloading pystac-1.14.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/miniconda3/lib/python3.12/site-packages (from copernicusmarine) (2.31.0)\n",
      "Collecting semver>=3.0.2 (from copernicusmarine)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in /opt/miniconda3/lib/python3.12/site-packages (from copernicusmarine) (68.2.2)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/miniconda3/lib/python3.12/site-packages (from copernicusmarine) (4.65.0)\n",
      "Requirement already satisfied: xarray>=2023.4.0 in /opt/miniconda3/lib/python3.12/site-packages (from copernicusmarine) (2025.10.1)\n",
      "Collecting zarr>=2.13.3 (from copernicusmarine)\n",
      "  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas<3,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from arcosparse<0.5.0,>=0.4.2->copernicusmarine) (2.3.3)\n",
      "Collecting pyarrow>=17.0.0 (from arcosparse<0.5.0,>=0.4.2->copernicusmarine)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-macosx_12_0_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting h5py (from h5netcdf<2.0.0,>=1.4.0->copernicusmarine)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.12/site-packages (from h5netcdf<2.0.0,>=1.4.0->copernicusmarine) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas<3,>=2->arcosparse<0.5.0,>=0.4.2->copernicusmarine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas<3,>=2->arcosparse<0.5.0,>=0.4.2->copernicusmarine) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas<3,>=2->arcosparse<0.5.0,>=0.4.2->copernicusmarine) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.1->copernicusmarine)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.9.1->copernicusmarine)\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.1->copernicusmarine) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.9.1->copernicusmarine)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.27.1->copernicusmarine) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.27.1->copernicusmarine) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.27.1->copernicusmarine) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.27.1->copernicusmarine) (2025.8.3)\n",
      "Collecting botocore<1.41.0,>=1.40.60 (from boto3>=1.26->copernicusmarine)\n",
      "  Downloading botocore-1.40.60-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.26->copernicusmarine)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.26->copernicusmarine)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=2->arcosparse<0.5.0,>=0.4.2->copernicusmarine) (1.17.0)\n",
      "Collecting cloudpickle>=3.0.0 (from dask>=2022->copernicusmarine)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask>=2022->copernicusmarine)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting partd>=1.4.0 (from dask>=2022->copernicusmarine)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from dask>=2022->copernicusmarine) (6.0.3)\n",
      "Collecting toolz>=0.10.0 (from dask>=2022->copernicusmarine)\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask>=2022->copernicusmarine)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting donfig>=0.8 (from zarr>=2.13.3->copernicusmarine)\n",
      "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr>=2.13.3->copernicusmarine)\n",
      "  Downloading numcodecs-0.16.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr>=2.13.3->copernicusmarine)\n",
      "  Downloading crc32c-2.8-cp312-cp312-macosx_10_13_x86_64.whl.metadata (7.8 kB)\n",
      "Downloading copernicusmarine-2.2.3-py3-none-any.whl (115 kB)\n",
      "Downloading arcosparse-0.4.2-py3-none-any.whl (26 kB)\n",
      "Downloading h5netcdf-1.7.3-py3-none-any.whl (56 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-macosx_10_12_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pystac-1.14.1-py3-none-any.whl (207 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading boto3-1.40.60-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.40.60-py3-none-any.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading dask-2025.10.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-macosx_12_0_x86_64.whl (36.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading zarr-3.1.3-py3-none-any.whl (276 kB)\n",
      "Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
      "Downloading numcodecs-0.16.3-cp312-cp312-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading crc32c-2.8-cp312-cp312-macosx_10_13_x86_64.whl (63 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-macosx_10_13_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: typing-inspection, toolz, semver, pydantic-core, pyarrow, numcodecs, locket, jmespath, h5py, fsspec, donfig, crc32c, cloudpickle, click, annotated-types, pystac, pydantic, partd, h5netcdf, botocore, zarr, s3transfer, dask, arcosparse, boto3, copernicusmarine\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [copernicusmarine][boto3]re]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 arcosparse-0.4.2 boto3-1.40.60 botocore-1.40.60 click-8.3.0 cloudpickle-3.1.1 copernicusmarine-2.2.3 crc32c-2.8 dask-2025.10.0 donfig-0.8.1.post1 fsspec-2025.9.0 h5netcdf-1.7.3 h5py-3.15.1 jmespath-1.0.1 locket-1.0.0 numcodecs-0.16.3 partd-1.4.2 pyarrow-22.0.0 pydantic-2.12.3 pydantic-core-2.41.4 pystac-1.14.1 s3transfer-0.14.0 semver-3.0.4 toolz-1.1.0 typing-inspection-0.4.2 zarr-3.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install copernicusmarine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71769f3b-7a71-4b11-ae4a-7e9a2e9b5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copernicusmarine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef69baae-8651-4656-8421-9692d10d1f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mcopernicusmarine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdataset_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdataset_version\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdataset_part\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musername\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpassword\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminimum_longitude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaximum_longitude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminimum_latitude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaximum_latitude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminimum_depth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaximum_depth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvertical_axis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'depth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'elevation'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'depth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart_datetime\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtslibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mend_datetime\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtslibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminimum_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaximum_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminimum_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaximum_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcoordinates_selection_method\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inside'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'strict-inside'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'outside'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inside'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_filename\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfile_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'netcdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zarr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'parquet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'netcdf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mservice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrequest_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_directory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcredentials_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmotu_api_request\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moverwrite\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskip_existing\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdry_run\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisable_progress_bar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstaging\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnetcdf_compression_level\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnetcdf3_compatible\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunk_size_limit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mraise_if_updating\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mplatform_ids\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mcopernicusmarine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponseSubset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Extract a subset of data from a specified dataset using given parameters.\n",
       "\n",
       "The datasetID is required and can be found via the ``describe`` command.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "dataset_id : str, optional\n",
       "    The datasetID, required either as an argument or in the request_file option.\n",
       "dataset_version : str, optional\n",
       "    Force the selection of a specific dataset version.\n",
       "dataset_part : str, optional\n",
       "    Force the selection of a specific dataset part.\n",
       "username : str, optional\n",
       "    If not set, search for environment variable COPERNICUSMARINE_SERVICE_USERNAME, then search for a credentials file, else ask for user input. See also :func:`~copernicusmarine.login`\n",
       "password : str, optional\n",
       "    If not set, search for environment variable COPERNICUSMARINE_SERVICE_PASSWORD, then search for a credentials file, else ask for user input. See also :func:`~copernicusmarine.login`\n",
       "variables : List[str], optional\n",
       "    List of variable names to extract.\n",
       "minimum_longitude : float, optional\n",
       "    Minimum longitude for the subset. The value will be transposed to the interval [-180; 360[.\n",
       "maximum_longitude : float, optional\n",
       "    Maximum longitude for the subset. The value will be transposed to the interval [-180; 360[.\n",
       "minimum_latitude : float, optional\n",
       "    Minimum latitude for the subset. Requires a float from -90 degrees to +90.\n",
       "maximum_latitude : float, optional\n",
       "    Maximum latitude for the subset. Requires a float from -90 degrees to +90.\n",
       "minimum_x : float, optional\n",
       "    Minimum x-axis value for the subset. The units are considered in length (m, 100km...).\n",
       "maximum_x : float, optional\n",
       "    Maximum x-axis value for the subset. The units are considered in length (m, 100km...).\n",
       "minimum_y : float, optional\n",
       "    Minimum y-axis value for the subset. The units are considered in length (m, 100km...).\n",
       "maximum_y : float, optional\n",
       "    Maximum y-axis value for the subset. The units are considered in length (m, 100km...).\n",
       "minimum_depth : float, optional\n",
       "    Minimum depth for the subset. Requires a positive float (or 0).\n",
       "maximum_depth : float, optional\n",
       "    Maximum depth for the subset. Requires a positive float (or 0).\n",
       "vertical_axis : str, optional\n",
       "    Consolidate the vertical dimension (the z-axis) as requested: depth with descending positive values, elevation with ascending positive values. Default is depth.\n",
       "start_datetime : Union[datetime, str], optional\n",
       "    The start datetime of the temporal subset. Supports common format parsed by dateutil (https://dateutil.readthedocs.io/en/stable/parser.html).\n",
       "end_datetime : Union[datetime, str], optional\n",
       "    The end datetime of the temporal subset. Supports common format parsed by dateutil (https://dateutil.readthedocs.io/en/stable/parser.html).\n",
       "coordinates_selection_method : str, optional\n",
       "    If ``inside``, the selection retrieved will be inside the requested range. If ``strict-inside``, the selection retrieved will be inside the requested range, and an error will be raised if the values don't exist. If ``nearest``, the extremes closest to the requested values will be returned. If ``outside``, the extremes will be taken to contain all the requested interval. The methods ``inside``, ``nearest`` and ``outside`` will display a warning if the request is out of bounds.\n",
       "output_directory : Union[pathlib.Path, str], optional\n",
       "    The destination folder for the downloaded files. Default is the current directory.\n",
       "credentials_file : Union[pathlib.Path, str], optional\n",
       "    Path to a credentials file if not in its default directory (``$HOME/.copernicusmarine``). Accepts .copernicusmarine-credentials / .netrc or _netrc / motuclient-python.ini files.\n",
       "output_filename : str, optional\n",
       "    Save the downloaded data with the given file name (under the output directory).\n",
       "file_format : str, optional\n",
       "    Format of the downloaded dataset. Default to NetCDF '.nc'.\n",
       "overwrite : bool, optional\n",
       "    If specified and if the file already exists on destination, then it will be overwritten. By default, the toolbox creates a new file with a new index (eg 'filename_(1).nc').\n",
       "skip_existing : bool, optional\n",
       "    If the files already exists where it would be downloaded, then the download is skipped for this file. By default, the toolbox creates a new file with a new index (eg 'filename_(1).nc').\n",
       "service : str, optional\n",
       "    Force download through one of the available services using the service name among ['arco-geo-series', 'arco-time-series', 'omi-arco', 'static-arco', 'arco-platform-series'] or its short name among ['geoseries', 'timeseries', 'omi-arco', 'static-arco', 'platformseries'].\n",
       "request_file : Union[pathlib.Path, str], optional\n",
       "    Option to pass a file containing the arguments. For more information please refer to the documentation or use option ``--create-template`` from the command line interface for an example template.\n",
       "motu_api_request : str, optional\n",
       "    Option to pass a complete MOTU API request as a string. Caution, user has to replace double quotes \" with single quotes ' in the request.\n",
       "dry_run : bool, optional\n",
       "    If True, runs query without downloading data.\n",
       "netcdf_compression_level : int, optional\n",
       "    Specify a compression level to apply on the NetCDF output file. A value of 0 means no compression, and 9 is the highest level of compression available.\n",
       "netcdf3_compatible : bool, optional\n",
       "    Enable downloading the dataset in a netCDF3 compatible format.\n",
       "chunk_size_limit : int, default -1\n",
       "    Limit the size of the chunks in the dask array. Default is set to -1 which behaves similarly to 'chunks=auto' from ``xarray``. Positive integer values and '-1' are accepted. This is an experimental feature.\n",
       "raise_if_updating : bool, default False\n",
       "    If set, raises a :class:`copernicusmarine.DatasetUpdating` error if the dataset is being updated and the subset interval requested overpasses the updating start date of the dataset. Otherwise, a simple warning is displayed.\n",
       "platform_ids : List[str], optional\n",
       "    List of platform IDs to extract. Only available for platform chunked datasets.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "ResponseSubset\n",
       "    A description of the downloaded data and its destination.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\dns21kxq\\appdata\\local\\anaconda3\\lib\\site-packages\\copernicusmarine\\python_interface\\subset.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?copernicusmarine.subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c80a0d9c-2163-4105-9612-92e1aa60f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-05-23T09:03:50Z - Downloading Copernicus Marine data requires a Copernicus Marine username and password, sign up for free at: https://data.marine.copernicus.eu/register\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copernicus Marine username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  d.spring@bangor.ac.uk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copernicus Marine password:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-05-23T09:04:04Z - Selected dataset version: \"202311\"\n",
      "INFO - 2025-05-23T09:04:04Z - Selected dataset part: \"default\"\n",
      "INFO - 2025-05-23T09:04:10Z - Starting download. Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224216074208405d9422e08b5aa62ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-05-23T09:27:30Z - Successfully downloaded to cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseSubset(file_path=WindowsPath('cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc'), output_directory=WindowsPath('.'), filename='cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc', file_size=1705.2406641221373, data_transfer_size=3482.663083969466, variables=['mlotst'], coordinates_extent=[GeographicalExtent(minimum=118.33333587646484, maximum=289.4166564941406, unit='degrees_east', coordinate_id='longitude'), GeographicalExtent(minimum=-49.33333206176758, maximum=56.58333206176758, unit='degrees_north', coordinate_id='latitude'), TimeExtent(minimum='1993-01-01T00:00:00+00:00', maximum='2021-06-01T00:00:00+00:00', unit='iso8601', coordinate_id='time')], status='000', message='The request was successful.', file_status='DOWNLOADED')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copernicusmarine\n",
    "\n",
    "copernicusmarine.subset(\n",
    "  dataset_id=\"cmems_mod_glo_phy_my_0.083deg_P1M-m\",\n",
    "  variables=[\"mlotst\"],\n",
    "  minimum_longitude=118.28409726039342,\n",
    "  maximum_longitude=289.44462136753623,\n",
    "  minimum_latitude=-49.41331005161829,\n",
    "  maximum_latitude=56.658000662667405,\n",
    "  start_datetime=\"1993-01-01T00:00:00\",\n",
    "  end_datetime=\"2021-06-01T00:00:00\",\n",
    "  minimum_depth=0.49402499198913574,\n",
    "  maximum_depth=0.49402499198913574,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb5af5d7-c5a0-4189-be2b-f353df3cac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import copernicusmarine\n",
    "print(copernicusmarine.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadbb630-e435-47b4-821f-9c3fc1bac711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dns21kxq\\\\OneDrive - Bangor University\\\\Upwelling_PhD'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking where the file has saved - it's in my OneDrive in Upwelling_PhD\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "600679f5-68af-4721-be07-4fa48b35e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, extract MLD and create csv with island coordinates \n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5385e7b9-9869-4969-a5c1-a50bd312fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open netcdf file\n",
    "ds = xr.open_dataset(\"cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "209f32e2-fc69-4594-b435-bece8563d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up island coordinates\n",
    "\n",
    "islands = pd.DataFrame({\n",
    "    \"Island\": [\n",
    "        \"Agrihan\", \"Aguijan\", \"Alamagan\", \"Asuncion\", \"Baker\", \"Farallon de Pajaros\",\n",
    "        \"French Frigate\", \"Guam\", \"Guguan\", \"Hawaii\", \"Howland\", \"Jarvis\", \"Johnston\",\n",
    "        \"Kauai\", \"Kingman\", \"Kure\", \"Lanai\", \"Lisianski\", \"Maug\", \"Maui\", \"Molokai\",\n",
    "        \"Niihau\", \"Oahu\", \"Ofu & Olosega\", \"Pagan\", \"Palmyra\", \"Pearl & Hermes\", \"Rose\",\n",
    "        \"Rota\", \"Saipan\", \"Sarigan\", \"Swains\", \"Tau\", \"Tinian\", \"Tutuila\"\n",
    "    ],\n",
    "    \"Longitude\": [\n",
    "        145.6655, 145.5540428, 145.8288224, 145.4019801, -176.4724867, 144.8935046,\n",
    "        -166.1471034, 144.7694362, 145.8414107, -155.5175818, -176.6183653, -159.9925287,\n",
    "        -169.5252208, -159.5427151, -162.4035451, -178.3357643, -156.9007932, -173.940815,\n",
    "        145.2225617, -156.4271816, -157.057521, -160.1490577, -157.980183, -169.6487833,\n",
    "        145.7598154, -162.0921952, -175.8099475, -168.1557562, 145.1784673, 145.7479009,\n",
    "        145.7772129, -171.0790122, -169.4649862, 145.6290474, -170.6796021\n",
    "    ],\n",
    "    \"Latitude\": [\n",
    "        18.76919755, 14.85052222, 17.59763189, 19.6901697, 0.195594452, 20.54286597,\n",
    "        23.76509266, 13.43555671, 17.30703766, 19.6531728, 0.807171192, -0.373640701,\n",
    "        16.75049417, 22.02797711, 6.401848114, 28.41578149, 20.82310913, 26.01765194,\n",
    "        20.0231279, 20.8274988, 21.12089198, 21.90649969, 21.46261758, -14.17102669,\n",
    "        18.10658672, 5.876541234, 27.87709112, -14.54492092, 14.14487969, 15.19841921,\n",
    "        16.70277819, -11.05599389, -14.23976999, 15.01948406, -14.29568942\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Convert longitudes to 0–360 range (as in CMEMS dataset)\n",
    "islands[\"Longitude\"] = islands[\"Longitude\"].apply(lambda x: x if x >= 0 else x + 360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1819e5da-ac4d-4216-b3f1-e5b8dd720d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract MLD values\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in islands.iterrows():\n",
    "    island = row[\"Island\"]\n",
    "    lat = row[\"Latitude\"]\n",
    "    lon = row[\"Longitude\"]\n",
    "    \n",
    "    # Extract time series using nearest lat/lon\n",
    "    subset = ds.mlotst.sel(latitude=lat, longitude=lon, method='nearest')\n",
    "\n",
    "    # Build a DataFrame from this series\n",
    "    island_df = pd.DataFrame({\n",
    "        \"Date\": subset.time.values,\n",
    "        \"Island\": island,\n",
    "        \"Latitude\": lat,\n",
    "        \"Longitude\": lon,\n",
    "        \"MLD\": subset.values\n",
    "    })\n",
    "    results.append(island_df)\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "mld_df = pd.concat(results, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3426d5a-aa06-48ac-9e06-9a78c62fe575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to csv\n",
    "\n",
    "mld_df.to_csv(\"island_mld_timeseries.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83036cde-4f0f-4695-97ec-352b271b6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next creating csv of site-specific values of MLD for full timeseries\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c64d51d2-c2a6-4bbe-8389-c817fec91fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4043dd3-256a-41af-aa54-930a26dba29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load site metadata\n",
    "sites = pd.read_csv(\"crep_lat_lon_site.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a5e1916-23a7-4c87-8dc2-5763071be1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Keep one entry per unique site (drop duplicates)\n",
    "sites_unique = sites.drop_duplicates(subset=\"SITE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d89e3ee3-471e-4f6c-8b66-2304e2141e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for i, row in sites_unique.iterrows():\n",
    "    site = row['SITE']\n",
    "    island = row['ISLAND']\n",
    "    lat = row['LATITUDE']\n",
    "    lon = row['LONGITUDE']\n",
    "\n",
    "    # Convert longitude to 0–360 if needed\n",
    "    if lon < 0:\n",
    "        lon = lon + 360\n",
    "\n",
    "    # Find nearest latitude and longitude indices\n",
    "    lat_idx = np.abs(ds['latitude'].values - lat).argmin()\n",
    "    lon_idx = np.abs(ds['longitude'].values - lon).argmin()\n",
    "\n",
    "    # Extract time series for this grid cell\n",
    "    mld_series = ds['mlotst'][:, lat_idx, lon_idx].values\n",
    "    dates = pd.to_datetime(ds['time'].values)\n",
    "\n",
    "    for date, mld in zip(dates, mld_series):\n",
    "        records.append({\n",
    "            \"Date\": date,\n",
    "            \"SITE\": site,\n",
    "            \"ISLAND\": island,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"MLD\": mld\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ed49508-0ba9-4bea-9144-03825d734005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! Saved as 'site_specific_MLD_timeseries.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe and export\n",
    "site_mld_df = pd.DataFrame(records)\n",
    "site_mld_df.to_csv(\"site_specific_MLD_timeseries.csv\", index=False)\n",
    "\n",
    "print(\"✅ Success! Saved as 'site_specific_MLD_timeseries.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
