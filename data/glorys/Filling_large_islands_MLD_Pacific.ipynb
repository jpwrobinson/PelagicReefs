{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9568e72b-1a46-4b7c-a599-dc5ed1728efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db35dfd9-c822-4bb7-ad35-562cec814417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dns21kxq'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking where the file has saved - it's in my OneDrive in Upwelling_PhD\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d5f9dd-d7a8-44d5-9685-746cf89f4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\dns21kxq\\\\OneDrive - Bangor University\\\\Upwelling_PhD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6348bd3e-a678-4da9-baed-94827ac0a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open netcdf file\n",
    "ds = xr.open_dataset(\"cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a2d9d6-4c07-43fa-837c-45c4a101b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure time is in datetime format\n",
    "ds['time'] = pd.to_datetime(ds['time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d126dc69-2778-4f30-b305-f336f6cedee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "start_date = \"1993-01-01\"\n",
    "end_date = \"2021-06-01\"\n",
    "times = pd.date_range(start=start_date, end=end_date, freq='MS')  # monthly start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baee8766-810c-4ee8-9313-dfd43d5c0f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install haversine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd27cea7-1b83-4de7-a2ba-770a9010d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine, Unit\n",
    "\n",
    "def find_nearest_ocean_point_fast(lat, lon, ds, var='MLD'):\n",
    "    # Convert 2D lat/lon grids\n",
    "    lat_grid, lon_grid = np.meshgrid(ds.latitude.values, ds.longitude.values, indexing='ij')\n",
    "\n",
    "    # Convert longitudes in dataset to [-180, 180] for haversine\n",
    "    lon_grid = np.where(lon_grid > 180, lon_grid - 360, lon_grid)\n",
    "\n",
    "    # Flatten and filter NaNs\n",
    "    sample = ds[var].isel(time=0).values\n",
    "    mask = ~np.isnan(sample)\n",
    "    valid_lats = lat_grid[mask]\n",
    "    valid_lons = lon_grid[mask]\n",
    "\n",
    "    # Vectorized haversine distance calculation\n",
    "    dists = np.array([\n",
    "        haversine((lat, lon), (la, lo), unit=Unit.KILOMETERS)\n",
    "        for la, lo in zip(valid_lats, valid_lons)\n",
    "    ])\n",
    "\n",
    "    idx = np.argmin(dists)\n",
    "    \n",
    "    # Get back 2D index\n",
    "    flat_idx = np.flatnonzero(mask)[idx]\n",
    "    lat_idx, lon_idx = np.unravel_index(flat_idx, sample.shape)\n",
    "    return lat_idx, lon_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d1b6acd-9201-4b0d-af6b-de09f2d9a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all input longitudes to [-180, 180]\n",
    "missing_islands = {\n",
    "    \"Guam\": (13.43556, 144.7694),\n",
    "    \"Hawaii\": (19.65317, 204.4824 - 360),\n",
    "    \"Kauai\": (22.02798, 200.4573 - 360),\n",
    "    \"Lanai\": (20.82311, 203.0992 - 360),\n",
    "    \"Lisianski\": (26.01765, 186.0592 - 360),\n",
    "    \"Maui\": (20.8275, 203.5728 - 360),\n",
    "    \"Oahu\": (21.46262, 202.0198 - 360),\n",
    "    \"Ofu & Olosega\": (-14.17103, 190.3512 - 360),\n",
    "    \"Rota\": (14.14488, 145.1785),\n",
    "    \"Tinian\": (15.01948, 145.629)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2949de37-e64c-42e8-a9c1-61ee45140260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_islands_data = []\n",
    "\n",
    "for island, (lat, lon) in missing_islands.items():\n",
    "    lat_idx, lon_idx = find_nearest_ocean_point_fast(lat, lon, ds, var='mlotst')\n",
    "    mld_timeseries = ds['mlotst'][:, lat_idx, lon_idx].to_series()\n",
    "    mld_timeseries = mld_timeseries.reset_index()\n",
    "    mld_timeseries['Island'] = island\n",
    "    all_islands_data.append(mld_timeseries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ebcc934-6446-459f-945f-66714d971c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "island_mld_filled = pd.concat(all_islands_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "072087c9-5433-4d8d-bbd2-9e443fb3088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load island mean MLD dataset\n",
    "df = pd.read_csv(\"island_mld_timeseries.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78ea5dcd-96a2-4082-833b-da0bee200e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original island data with the filled-in missing island MLD data\n",
    "combined_df = pd.concat([df, island_mld_filled], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4d8cc89-b7bf-4208-8975-35d8321cb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"island_mld_timeseries_filled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa85da11-db76-4580-a3ce-d3f8dadbf57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Above code didn't work - still getting NA values\n",
    "\n",
    "ds = xr.open_dataset('cmems_mod_glo_phy_my_0.083deg_P1M-m_mlotst_118.33E-289.42E_49.33S-56.58N_1993-01-01-2021-06-01.nc', decode_coords=\"all\", mask_and_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf7fd16-a1dd-4c7d-970f-91c9a19f2082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unit_long': 'Meters', 'long_name': 'Density ocean mixed layer thickness', 'valid_max': 23400, 'units': 'm', 'valid_min': 1, 'standard_name': 'ocean_mixed_layer_thickness_defined_by_sigma_theta'}\n"
     ]
    }
   ],
   "source": [
    "print(ds['mlotst'].attrs)  # Look for _FillValue or missing_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78c11dea-bf74-42d5-802d-1cd76281fad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit_long': 'Meters',\n",
       " 'long_name': 'Density ocean mixed layer thickness',\n",
       " 'valid_max': 23400,\n",
       " 'units': 'm',\n",
       " 'valid_min': 1,\n",
       " 'standard_name': 'ocean_mixed_layer_thickness_defined_by_sigma_theta'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['mlotst'].attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20b33543-6d68-4416-a4a7-c891cb9c4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time        MLD Island\n",
      "0 1993-01-01  41.924804   Guam\n",
      "1 1993-02-01  35.897398   Guam\n",
      "2 1993-03-01  25.902586   Guam\n",
      "3 1993-04-01  22.392957   Guam\n",
      "4 1993-05-01  18.768884   Guam\n"
     ]
    }
   ],
   "source": [
    "### Instead, calculating a mean MLD value for each island covered by land, for each time step\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Island coordinates (in decimal degrees; longitudes should be 0–360)\n",
    "islands = {\n",
    "    'Guam': (13.43556, 144.7694), \n",
    "    'Hawaii': (19.65317, 204.4824),\n",
    "    'Kauai': (22.02798, 200.4573),\n",
    "    'Lanai': (20.82311, 203.0992),\n",
    "    'Lisianski': (26.01765, 186.0592),\n",
    "    'Maui': (20.8275, 203.5728),\n",
    "    'Oahu': (21.46262, 202.0198),\n",
    "    'Ofu & Olosega': (-14.17103, 190.3512),\n",
    "    'Rota': (14.14488, 145.1785),\n",
    "    'Tinian': (15.01948, 145.629),\n",
    "}\n",
    "\n",
    "# Helper: find index of nearest coordinate\n",
    "def find_nearest_idx(array, value):\n",
    "    return np.abs(array - value).argmin()\n",
    "\n",
    "# Loop over islands\n",
    "island_timeseries = []\n",
    "\n",
    "for island, (lat, lon) in islands.items():\n",
    "    # Ensure longitude is 0–360\n",
    "    if lon < 0:\n",
    "        lon = lon + 360\n",
    "    \n",
    "    # Find nearest grid cell indices\n",
    "    lat_idx = find_nearest_idx(ds.latitude.values, lat)\n",
    "    lon_idx = find_nearest_idx(ds.longitude.values, lon)\n",
    "\n",
    "    # Define a small window around the grid cell (e.g., 3x3 neighborhood)\n",
    "    lat_slice = slice(max(lat_idx - 1, 0), min(lat_idx + 2, len(ds.latitude)))\n",
    "    lon_slice = slice(max(lon_idx - 1, 0), min(lon_idx + 2, len(ds.longitude)))\n",
    "\n",
    "    # Extract the 3x3 surrounding MLD values for each timestep\n",
    "    mld_sub = ds['mlotst'][:, lat_slice, lon_slice]\n",
    "\n",
    "    # Compute mean across spatial dims, ignoring NaNs\n",
    "    mld_mean = mld_sub.mean(dim=['latitude', 'longitude'], skipna=True)\n",
    "\n",
    "    # Turn into DataFrame\n",
    "    island_df = mld_mean.to_dataframe(name='MLD').reset_index()\n",
    "    island_df['Island'] = island\n",
    "\n",
    "    island_timeseries.append(island_df)\n",
    "\n",
    "# Combine all islands\n",
    "result_df = pd.concat(island_timeseries, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d12e562c-aefa-4c28-90ff-d394eb23893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"MLD_timeseries_by_island_FILLED.csv\", index=False)\n",
    "\n",
    "## Worked for all except Hawaii and Oahu - next, solution for these 2 islands using bigger grid area surrounding islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "355df280-4b3a-46d9-9223-c783d8a25413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Island  MLD_5x5_mean\n",
      "0 1993-01-01  Hawaii           NaN\n",
      "1 1993-02-01  Hawaii           NaN\n",
      "2 1993-03-01  Hawaii           NaN\n",
      "3 1993-04-01  Hawaii           NaN\n",
      "4 1993-05-01  Hawaii           NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dns21kxq\\AppData\\Local\\Temp\\ipykernel_6160\\3760519329.py:28: RuntimeWarning: Mean of empty slice\n",
      "  window_mean = np.nanmean(window_data)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_mld_5x5(ds, lat, lon, island_name):\n",
    "    lat_grid, lon_grid = np.meshgrid(ds.latitude.values, ds.longitude.values, indexing='ij')\n",
    "    lon_grid = np.where(lon_grid < 0, lon_grid + 360, lon_grid)  # Normalize longitude if needed\n",
    "    \n",
    "    # Find nearest grid cell indices\n",
    "    lat_idx = (np.abs(ds.latitude.values - lat)).argmin()\n",
    "    lon_idx = (np.abs(lon_grid[0] - lon)).argmin()\n",
    "\n",
    "    # Define window size and half window\n",
    "    window_size = 5\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    # Initialize list to hold mean MLD for each timestep\n",
    "    mean_mld = []\n",
    "\n",
    "    # Loop through time dimension\n",
    "    for t in range(len(ds.time)):\n",
    "        # Extract 5x5 window slice with bounds check\n",
    "        lat_min = max(0, lat_idx - half_window)\n",
    "        lat_max = min(len(ds.latitude) - 1, lat_idx + half_window)\n",
    "        lon_min = max(0, lon_idx - half_window)\n",
    "        lon_max = min(len(ds.longitude) - 1, lon_idx + half_window)\n",
    "\n",
    "        window_data = ds['mlotst'][t, lat_min:lat_max+1, lon_min:lon_max+1].values\n",
    "        window_mean = np.nanmean(window_data)\n",
    "        mean_mld.append(window_mean)\n",
    "    \n",
    "    # Create DataFrame for this island\n",
    "    df = pd.DataFrame({\n",
    "        'Date': ds.time.values,\n",
    "        'Island': island_name,\n",
    "        'MLD_5x5_mean': mean_mld\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Coordinates for the two islands\n",
    "islands_5x5 = {\n",
    "    'Hawaii': (19.65317, 204.4824),\n",
    "    'Oahu': (21.46262, 202.0198)\n",
    "}\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for island, (lat, lon) in islands_5x5.items():\n",
    "    island_df = extract_mld_5x5(ds, lat, lon, island)\n",
    "    results.append(island_df)\n",
    "\n",
    "# Combine into single DataFrame\n",
    "mld_5x5_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Now you can save or merge this data with your existing dataframe\n",
    "print(mld_5x5_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9131cb97-8dcb-4291-a3a7-aa5ac50ac905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest grid cell values for Hawaii at time 0: nan\n"
     ]
    }
   ],
   "source": [
    "# Check if the nearest grid cell is on NaN for Hawaii and Oahu\n",
    "\n",
    "lat_idx = (np.abs(ds.latitude.values - 19.65317)).argmin()\n",
    "lon_idx = (np.abs(ds.longitude.values - 204.4824)).argmin()\n",
    "print(\"Nearest grid cell values for Hawaii at time 0:\", ds['mlotst'][0, lat_idx, lon_idx].values)\n",
    "\n",
    "## Need bigger grid cell window - trying 7x7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c19d21a-8d86-45be-b99d-4d552b201fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Island  MLD_9x9_mean\n",
      "0 1993-01-01  Hawaii     56.001468\n",
      "1 1993-02-01  Hawaii     49.134803\n",
      "2 1993-03-01  Hawaii     32.959992\n",
      "3 1993-04-01  Hawaii     20.447402\n",
      "4 1993-05-01  Hawaii     18.768884\n"
     ]
    }
   ],
   "source": [
    "# Islands dictionary for just Hawaii and Oahu, if you want\n",
    "islands_7x7 = {\n",
    "    'Hawaii': (19.65317, 204.4824),\n",
    "    'Oahu': (21.46262, 202.0198)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for island, (lat, lon) in islands_7x7.items():\n",
    "    df = extract_mld_window(ds, lat, lon, island, window_size=9)  # window_size=9 here\n",
    "    results.append(df)\n",
    "\n",
    "mld_df_9x9 = pd.concat(results, ignore_index=True)\n",
    "print(mld_df_9x9.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff48fc46-fe65-4241-8fc8-d6c3e7dd99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_df_9x9.to_csv(\"MLD_timeseries_Hawaii_Oahu_FILLED.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
